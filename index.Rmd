---
title: "스팸 메일 분류로 배우는 머신러닝 Using R"
output: github_document
---

안녕하세요. 이번 글에서는 [권재명](https://dataninja.me/ipds-kr/)선생님께서 쓰신 책의 주제와 코드를 중심으로 

`의사결정나무(Decision Tree)`와 앙상블(Ensemble) 기법 중 하나인 `랜덤포레스트(Random Forest)`를 활용하여

스팸 메일을 분류하는 모델을 학습시켜 보도록 하겠습니다. 

우선 데이터는 [CUI Machine Learning Reapository](https://archive.ics.uci.edu/ml/datasets/Spambase)에서 'spambase.data', 'spambase.names' 파일을

setwd로 설정한 디렉토리에 다운받아 저장합니다. 

reference: Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.


해당 데이터에 대한 자세한 설명은 [링크](https://docs.google.com/presentation/d/1BKo0O1ItmWXmsvab_R_wvrZCBtTVBwbhUszA1u5ZmI0/edit#slide=id.g2366bcb1b2_0_57)를 참고해주세요.

요약하자면, 

 - 행: 4,601(사례), 열: 58(변수/Feature)
 
 - 58번째 Feature는 `Label Data`로 스팸인 지(spam=1) 아닌지(=0)를 나타냄
 
 
## 연구 절차는 다음과 같습니다. 
 - 시스템 세팅
 - 데이터 이해(기초 분석 및 시각화)
 - 데이터 분할
 - 의사결정나무 모형(Decision Tree)
 - 랜덤포레스트(Random Forest)
 - 모형 평가, 해석 및 선택
 

### 시스템 세팅

먼저 관련 패키지를 설치하고, 불러옵니다.

```{r setup}
#install.packages(c( "randomForest", "rpart","boot","data.table", caret" ))
#install.packages(c( "rattle", "rpart.plot", "RColorBrewer", "e1071"))

library(dplyr); library(ggplot2); library(MASS); library(randomForest); library(rpart); library(boot); library(data.table); library(caret)

```

다음으로는 데이터를 로드합니다. 

```{r data_load}

data <- tbl_df(read.table("spambase.data", strip.white = TRUE,
                          sep=",", header = FALSE)) #dplyr 패키지 함수 입니다.
                                                    #해당 파일이 워크디렉토리안에 저장되어 있어야 합니다. 
names(data) <- #Feature의 이름을 입력합니다.
  c('word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our',
    'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail',
    'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses',
    'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit',
    'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp',
    'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs',
    'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',
    'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct',
    'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re',
    'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_;', 'char_freq_(',
    'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#', 'capital_run_length_average',
    'capital_run_length_longest', 'capital_run_length_total', 'class' #class 변수가 Label Data 입니다. 
  )

data$class <- factor(data$class) #범주형 변수로 변환(스팸메일 인지/아닌지 이기 때문에 범주형 입니다.)

```


### 데이터 이해(기초 분석 및 시각화)

간단한 코드를 통해 데이터에 대한 이해를 높일 수 있습니다. 

데이터의 내용을 이해하지 못하면, 머신러닝 모델 결과의 올바른 해석이 불가능합니다. 

또한 상관 계수와 산점도를 확인해 보는 것도 데이터의 이해를 높이는데 좋은 방법입니다. 


```{r data_understanding}

glimpse(data) #str(data) 비교해보는 것도 좋을 것 같습니다. 
summary(data)
```


```{r correlation}
data_1 <- subset(data, select = c(word_freq_make, word_freq_address, word_freq_all, class)) 
#모든 변수를 한꺼번에 그리는 것이 쉽지 않아, 부분적으로 먼저 확인해보겠습니다. 

#아래 코드는 산점도 행렬의 위쪽에 상관계수 숫자를 집어넣는 사용자 정의 함수 입니다. 
#출처: https://rfriend.tistory.com/83 [R, Python 분석과 프로그래밍의 친구 (by R Friend)]

panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y))
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste0(prefix, txt)
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = cex.cor * r * 5)
} 

pairs(data_1,
      upper.panel = panel.cor, # 위쪽에는 상관계수 비례) 
      pch="*" 
      )

```

```{r Feature}
#57개 Feature 중 Label Data의 Class와 상관 관계가 가장 높은 변수는 어떤 변수인지 살펴보겠습니다. 
tmp <- as.data.frame(cor(data[,-58], as.numeric(data$class))) 
tmp <- tmp %>% rename(cor=V1)
tmp$var <- rownames(tmp)
tmp %>%
  ggplot(aes(reorder(var, cor), cor)) +
  geom_point() +
  coord_flip()
```




### 데이터 분할

데이터 분할에 앞서서 데이터 전처리 과정이 필요합니다. 

본 데이터는 [CUI Machine Learning Reapository](https://archive.ics.uci.edu/ml/datasets/Spambase)에서 전처리가 되어 제공되는 데이터지만, 

본 연구에서 적용하는 RandomForest 패키지에서는 특수문자가 포함된 Feature는 모델에 사용할 수 없습니다.[권재명(2017)](https://dataninja.me/ipds-kr/)

따라서, `make.names`함수를 활용하여 이 문제를 해결합니다.

```{r preprocessing}

old_names <- names(data)
new_names <- make.names(names(data), unique = TRUE)
cbind(old_names, new_names) [old_names!=new_names, ]

names(data) <- new_names

```

다음으로 `caret`패키지를 활용하여 데이터를 분할합니다.

여러가지 데이터 분할 방법이 있지만, 저는 이 방법이 가장 편하고 익숙합니다.^^

```{r data bunhal}

intrain<-createDataPartition(y=data$class, p=0.7, list=FALSE) 
train<-data[intrain, ] #학습용 데이터 셋
test<-data[-intrain, ] #평가용 데이터 셋

```

### Decision Tree

일반적으로 트리를 생성할 때 [R에서는 tree, rpart, party와 같은 패키지를 많이 활용합니다.](http://www.dodomira.com/2016/05/29/564/)

하지만, 강력한 시각화를 장점으로 하고 있는 R에서 유독 Decision Tree만 시각화를 하면 괜히 미안해집니다. 

이를 위해 [DODOMIRA님](http://www.dodomira.com/2016/07/19/r-%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4-%EA%B9%94%EB%81%94%ED%95%98%EA%B2%8C-plotting-%ED%95%98%EA%B8%B0-fancyrpartplot-r/)께서 제시하신 rattle 패키지의 fancyrpartplot 함수를 활용한 방법으로 트리를 플로팅하였습니다. 

트리 해석 또한 [해당 블로그](http://www.dodomira.com/2016/07/19/r-%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4-%EA%B9%94%EB%81%94%ED%95%98%EA%B2%8C-plotting-%ED%95%98%EA%B8%B0-fancyrpartplot-r/)를 참고하시면 될 것 같습니다. 

```{r tree_1}
#install.packages(c("rattle", "rpart.plot", "RColorBrewer"))
library(rattle)				    # Fancy tree plot
library(rpart.plot)			  # Enhanced tree plots
library(RColorBrewer)			# Color selection for fancy tree 

```

```{r tree_2}
rpart_spam<-rpart(class~. , data=data, method="class")
plot(rpart_spam); text(rpart_spam)      #원래 rpart 패키지 트리
```

```{r tree_3}
printcp(rpart_spam); plotcp(rpart_spam) #과적합 방지를 위해 cp(Complexity Parameter, 복잡성 매개변수)값을 통해 가지치기 실시
```

```{r tree_4}
rpart_spam_pruning <-prune(rpart_spam, 
                           cp = rpart_spam$cptable[which.min(rpart_spam$cptable[,"xerror"]),"CP"]
                           )            #cp값으로 가지치기 한 트리 생성

summary(rpart_spam_pruning)             #트리 요약값 정리
```

```{r tree_5}
fancyRpartPlot(rpart_spam_pruning,      #fancy한 트리 생성
               cex = 1
               )   
```

```{r tree_6}
rpart_spam_predict<-predict(rpart_spam_pruning, test, type ='class')
confusionMatrix(rpart_spam_predict, test$class) #생성된 트리 모형의 평가(정확도, 민감도, 특이도 등)

```

### Random Forest

`랜덤포레스트`에 대한 설명은 [링크](http://civil.colorado.edu/~balajir/CVEN6833/lectures/cluster_lecture-2.pdf)를 참고해주세요.

```{r randomforest_1}

data_rf <- randomForest(class ~ ., data = train)
data_rf
```

```{r randomforest_2}

plot(data_rf) #나무의 갯수에 따른 오차율
```

```{r randomforest_3}
varImpPlot(data_rf) #변수 중요도(그래프에서 상단에 있을 경우 Label Data의 Class을 분류하는데 모델이 많이 활용하는 변수)
```

```{r randomforest_4}
data_rf_predict <- predict(data_rf, test, type = "class")
confusionMatrix(data = data_rf_predict, reference=test$class) #생성된 RF모형의 평가(정확도, 민감도, 특이도 등)

```

### 모형 평가, 해석 및 선택

모형의 평가는 분류모형의 경우 [혼동행렬(Confusion Matrix)](https://www.geeksforgeeks.org/confusion-matrix-machine-learning/)에 기반하여 각 모형에 대한 정확도, 민감도, 특이도 등을 고려하여 종합적으로 평가하게 됩니다. 

평가의 결과를 통해 두 모형 중 어떠한 모형으로 결정할 지 선택하게 됩니다. 


시간이 너무 늦어 자세한 내용은 추후 업데이트하겠습니다. 

오늘도 감사합니다.^^


